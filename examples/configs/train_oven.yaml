defaults:
  - env_vars: env_vars
  - _self_

seed: 42
window_size: 50
goal_window_size: 10
eval_window_size: 10
batch_size: 1024
epochs: 500
eval_freq: 10
eval_on_env_freq: 10
num_env_evals: 20
num_final_evals: 20
num_final_eval_per_goal: 5
action_window_size: 20
sequentially_select: false
action_mode: "f"
noise_enhance_coef: 0.05
visual_input: false # true: image-based policy, false: state-based policy
predict_contact: true
# normalization scale= 10
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-03-31/21-54-19/pretrain_oven/trained_vqvae.pt"
# normalization scale = 1 (Used when train the 0-start_angle task.)
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-04-05/19-51-20/pretrain_oven/trained_vqvae.pt"
# full state
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-04-03/19-44-48/pretrain_oven/trained_vqvae.pt"
# full state and decrease vq_loss
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-04-04/12-57-49/pretrain_oven/trained_vqvae.pt" 
# full state
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-04-05/18-59-36/pretrain_oven/trained_vqvae.pt"
# res state different start state
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-04-14/19-30-48/pretrain_oven/trained_vqvae.pt"
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-04-15/14-57-47/pretrain_oven/trained_vqvae.pt"
# res_iter_Task_4
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-05-02/08-26-09/pretrain_oven/trained_vqvae.pt"
# res_iter_Task_5 
# vqvae_load_dir: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/oven/2024-06-04/11-12-48/pretrain_oven/trained_vqvae.pt"
# res_iter_Task_6
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-03/23-51-16/pretrain_oven/trained_vqvae.pt"

# rand res state, corrected
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-08/23-43-13/pretrain_oven/trained_vqvae.pt"
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-08/23-43-13/pretrain_oven/trained_vqvae.pt"
# res gaussian
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-16/00-29-39/pretrain_oven/trained_vqvae.pt"
# res contact
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-16/19-56-02/pretrain_oven/trained_vqvae.pt"
# rand full state, corrected
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-08/23-41-01/pretrain_oven/trained_vqvae.pt"


# dof_vel
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-14/15-16-47/pretrain_oven/trained_vqvae.pt"

# contact
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-16/00-29-39/pretrain_oven/trained_vqvae.pt"

# full distance
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-25/13-54-54/pretrain_oven/trained_vqvae.pt"
# res distance
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-07-31/22-52-02/pretrain_oven/trained_vqvae.pt"
# res_state, for visual input, state_dim = 37
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-09-18/11-40-24/pretrain_oven/resstate/trained_vqvae.pt"

# state-input residual-action oven-opening, real_robot_employment  
vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-10-01/13-34-37/pretrain_oven/OvenOpening_res/trained_vqvae.pt"
# state-input fullstate-action oven-opening, real_robot_employment
# vqvae_load_dir: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_vq_vae/2024-10-01/13-35-03/pretrain_oven/OvenOpening_fullstate/trained_vqvae.pt"

goal_dim: 0

wandb:
  project: "vq-bet"
  run_name: "transformer_state/"
  entity: ${env_vars.wandb_entity}

device: cuda
optim:
  lr: 5.5e-5
  weight_decay: 2e-4
  betas: [0.9, 0.999]
  sync_lr: false
  lr_num_warmup_steps: 500

env:
  gym:
    _target_: kitchen_env.KitchenWrapper
    id: kitchen-v0
    env:
      _target_: gym.make
      id: kitchen-v0
    visual_input: ${visual_input}
  obs_dim: 46
  act_dim: 48
  goal_dim: ${goal_dim}

data:
  _target_: dataset.get_alma_train_val
  # data_directory: ${env_vars.datasets.oven}
  # data_directory: /home/anqiao/MasterThesis/Data/OvenOpening/pt/output_fullstate
  data_directory: /media/anqiao/AnqiaoT7/MasterThesis/Data/OvenOpening/pt/Task_10/OvenOpening/data/state_dataset.h5
  res_action: false
  goal_conditional: future
  window_size: ${window_size}
  future_seq_len: ${goal_window_size}
  min_future_sep: ${action_window_size}
  action_window_size: ${action_window_size}
  vqbet_get_future_action_chunk: true
  padding: "None"
  visual_input: ${visual_input}
  load_traj_num: 200
  res_action: false

save_every: 10
save_path: "${env_vars.save_path}/checkpoints/${env.gym.id}/${now:%Y-%m-%d}/${now:%H-%M-%S}"
# load_path:  "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-02/20-56-20/sleek-pond-23"
# load_path:  "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-03/11-50-56/pious-puddle-28"
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-03/12-01-17/breezy-firefly-30"
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-03/14-32-04/dark-darkness-42"
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-03/14-32-04/dark-darkness-42"
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-03/15-30-42/dashing-fire-44"
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-03/20-29-35/ethereal-terrain-53"
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-03/21-23-23/lucky-pine-55"

# 0-angle res-iter
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-07/00-43-27/nagus-nimoy-93"
# 0-1.2 res-iter
# load_path: "/home/anqiao/MasterThesis/Checkpoints/euler/oven_transformer/2024-05-02/14-22-40/young-eon-486"
# 0-1.2 res
# load_path: "/home/anqiao/MasterThesis/Checkpoints/VQ-BeT/checkpoints/kitchen-v0/2024-04-16/09-39-55/rich-terrain-106"
# load_path: "/home/anqiao/MasterThesis/Checkpoints/euler/checkpoints/oven_transformer/2024-05-02/01-01-16/cerulean-resonance-484"

# task 6 res
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-07-04/09-36-54/worldly-glade-535"

# rand res state, corrected
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-07-09/16-17-09/apricot-music-541"
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-07-16/01-22-25/lyric-violet-590"
# rand full state, corrected
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-07-09/10-00-46/revived-dragon-540"

# rand res state, gaussian
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-07-16/01-23-26/pleasant-field-591"

# res_state_contact
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-07-17/00-08-34/lyric-tree-615"

# full state distance, sparse observation
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-07-27/07-22-36/silvery-violet-664"

# res state distance, sparse observation
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-08-13/01-19-05/frosty-tree-705"

# res_state, no visual input, state_dim = 37
# load_path: "/media/anqiao/AnqiaoT7/MasterThesis/Checkpoints/euler/oven_transformer/2024-09-18/15-12-38/transformer/resstate_a20"

load_path: None


model:
  _target_: vq_behavior_transformer.BehaviorTransformer
  obs_dim: ${env.obs_dim}
  act_dim: ${env.act_dim}
  goal_dim: ${env.goal_dim}
  obs_window_size: ${window_size}
  act_window_size: ${action_window_size}
  sequentially_select: ${sequentially_select}
  visual_input: ${visual_input}
  res_iter: true
  uniformly_downsample: 5
  gpt_model:
    _target_: vq_behavior_transformer.GPT
    config:
      _target_: vq_behavior_transformer.GPTConfig
      block_size: 110
      input_dim: ${env.obs_dim}
      n_layer: 6
      n_head: 6
      n_embd: 120
  vqvae_model:
    _target_: vqvae.VqVae
    obs_dim: ${env.obs_dim}
    input_dim_h: ${action_window_size}
    input_dim_w: ${env.act_dim}
    n_latent_dims: 512
    vqvae_n_embed: 16
    vqvae_groups: 2
    eval: true
    device: ${device}
    load_dir: ${vqvae_load_dir}
    act_scale: 1
    normalization: true
  offset_loss_multiplier: 100
  secondary_code_multiplier: 1
  clip_phase_output: true

goal_fn:
  _target_: kitchen_env.get_goal_fn
  data_directory: ${env_vars.datasets.relay_kitchen}
  goal_conditional: ${data.goal_conditional}
  seed: ${seed}
  train_fraction: 0.95
  goal_seq_len: ${goal_window_size}
  unconditional: false
  goal_dim: ${goal_dim}
  visual_input: ${visual_input}

obs_noise:
  _target_: obs_noise.ObsNoise
  input_mode: "state_input"
  obs_dim: ${env.obs_dim}

